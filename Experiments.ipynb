{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import models, layers, datasets\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, Input, InputLayer\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from load_MNIST import load_MNIST\n",
    "from used_func import parameter_count,define_pruning_params,pruning_rounds,prune_network,encode_save_json,decode_json\n",
    "from model import pruned_nn\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the Strategy and the Pruning rate before starting the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Which round of the experiment that we are experimenting\n",
    "# we will get the summary statistics of these values to report\n",
    "#for compututional reasons we will make each round by hand unfortunately\n",
    "\n",
    "strategy=1\n",
    "exp_round=5\n",
    "pruning_percentage=0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Setting random seed\n",
    "#in order to have reproducible results each round will have specific random seed\n",
    "\n",
    "print('Starting the experiment...')\n",
    "\n",
    "np.random.seed(41+exp_round)\n",
    "tf.random.set_seed(41+exp_round)\n",
    "\n",
    "## import the summary data to save our experiments result on\n",
    "\n",
    "#first let's create the folder\n",
    "\n",
    "data_dirname='Data'\n",
    "\n",
    "if not os.path.exists(data_dirname):\n",
    "    os.mkdir(data_dirname)\n",
    "    print(\"Directory \" , data_dirname ,  \" Created \")\n",
    "else:    \n",
    "    print(\"Directory \" , data_dirname ,  \" already exists\")\n",
    "\n",
    "summary_data='summary_data.csv'\n",
    "\n",
    "if os.path.exists('{}/{}'.format(data_dirname,summary_data)):\n",
    "    # import the main Pandas document\n",
    "    df_main=pd.read_csv('{}/{}'.format(data_dirname,summary_data))\n",
    "    print('Summary Data Loaded Succesfully')\n",
    "else:\n",
    "    df_main=pd.DataFrame()\n",
    "    print('Summary Data Created Succesfully')\n",
    "\n",
    "# creating a folder for the original networks weight    \n",
    "    \n",
    "orig_dirname='Orig_weights'\n",
    "\n",
    "if not os.path.exists(orig_dirname):\n",
    "    os.mkdir(orig_dirname)\n",
    "    print(\"Directory \" , orig_dirname ,  \" Created \")\n",
    "else:    \n",
    "    print(\"Directory \" , orig_dirname ,  \" already exists\")\n",
    "\n",
    "\n",
    "# loads, normalizes and preprocesses the MNIST dataset\n",
    "\n",
    "print('Loading the data...')\n",
    "\n",
    "X_train,y_train,X_test,y_test=load_MNIST()\n",
    "\n",
    "#creating the validation data out of the training set\n",
    "\n",
    "X_train, X_val, y_train,y_val=train_test_split(X_train,y_train,test_size=5000,stratify=y_train,random_state=42)\n",
    "\n",
    "# Assigning some variables for the experiment\n",
    "\n",
    "batch_size = 60 #according to the paper\n",
    "epochs = 50 #this is the number of the training iterations in the original paper. However we will use early stopping\n",
    "#to stop the training\n",
    "num_classes = y_test.shape[1]\n",
    "\n",
    "#patience is for the early stopping, if there is no mitigation in the validation loss, training will stop\n",
    "patience=5\n",
    "minimum_delta = 0.001\n",
    "\n",
    "# input image dimensions\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "\n",
    "#Number of the units in the layers\n",
    "first_layer=300\n",
    "second_layer=100\n",
    "layer_pruning_rounds=11 #It is possible to modify this, we choose for the 11 rounds\n",
    "\n",
    "#Target sparsity for iterative pruning process. See the method section our paper\n",
    "#this is modifiable as well.\n",
    "target=0.036\n",
    "\n",
    "\n",
    "#Creating the smaller network sizes\n",
    "\n",
    "layers_model=list()\n",
    "layers_model.append((first_layer,second_layer))\n",
    "for i in range(layer_pruning_rounds):\n",
    "    first_layer-=np.ceil(first_layer*0.2).astype(int)\n",
    "    second_layer-=np.ceil(second_layer*0.2).astype(int)\n",
    "    layers_model.append((first_layer,second_layer))\n",
    "\n",
    "print('Network sizes for the experiments:')\n",
    "print(layers_model)\n",
    "\n",
    "\n",
    "# Create training and testing datasets for Tensorflow GradientTape\n",
    "# Create training and testing datasets for Tensorflow\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size = 55000, reshuffle_each_iteration = True).batch(batch_size = batch_size, drop_remainder = False)\n",
    "val_dataset = val_dataset.batch(batch_size=batch_size, drop_remainder=False)\n",
    "test_dataset = test_dataset.batch(batch_size=batch_size, drop_remainder=False)\n",
    "\n",
    "layers = tf.keras.layers\n",
    "\n",
    "# Specify the parameters to be used for layer-wise pruning, NO PRUNING is done here:\n",
    "# This is necessary because we decided to use same model for every experiments\n",
    "# so this unpruned network has to be defined\n",
    "pruning_params_unpruned = define_pruning_params()\n",
    "\n",
    "# This is necessary for the model to work with Tensorflow-Optimization API\n",
    "callbacks = [\n",
    "             sparsity.UpdatePruningStep(),\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "## Initialize the Lenet-300-100 model\n",
    "\n",
    "#This model will be used to determine _super winning tickets_\n",
    "\n",
    "print('Original Lenet 300-100 is training...')\n",
    "\n",
    "lenet_model = pruned_nn(pruning_params_unpruned,first_layer=300,second_layer=100)\n",
    "\n",
    "lenet_model_stripped = sparsity.strip_pruning(lenet_model)\n",
    "\n",
    "# Two dictionary is used for every model in the notebook\n",
    "# One for 1 epoch (1.000 iterations) that we decide early stopping to stop training\n",
    "# One for 100 iterations to decide validation loss and test accuracy in the work\n",
    "\n",
    "# Dictionary to hold scalar metrics-\n",
    "history_lenet = {}\n",
    "\n",
    "history_lenet['accuracy'] = np.zeros(epochs)\n",
    "history_lenet['val_accuracy'] = np.zeros(epochs)\n",
    "history_lenet['loss'] = np.zeros(epochs)\n",
    "history_lenet['val_loss'] = np.zeros(epochs)\n",
    "\n",
    "# Dictionary to hold scalar metrics-\n",
    "history_lenet_batch = {}\n",
    "\n",
    "history_lenet_batch['accuracy'] = np.zeros(epochs*10)\n",
    "history_lenet_batch['val_accuracy'] = np.zeros(epochs*10)\n",
    "history_lenet_batch['loss'] = np.zeros(epochs*10)\n",
    "history_lenet_batch['val_loss'] = np.zeros(epochs*10)\n",
    "\n",
    "lenet_model.save_weights(\"{}/Lenet_300_100_Randomly_Initialized_weights.h5\".format(orig_dirname), overwrite=True)\n",
    "\n",
    "# Instantiate a new neural network model for which, the mask is to be created,\n",
    "\n",
    "\n",
    "mask_model_lenet = pruned_nn(pruning_params_unpruned,300,100)\n",
    "\n",
    "# Load weights of the model-\n",
    "mask_model_lenet.load_weights(\"{}/Lenet_300_100_Randomly_Initialized_weights.h5\".format(orig_dirname))\n",
    "\n",
    "# Strip the model of its pruning parameters-\n",
    "mask_model_lenet_stripped = sparsity.strip_pruning(mask_model_lenet)\n",
    "\n",
    "# In this setup all the values in the masks will be equal to the 1 because there is no pruning\n",
    "\n",
    "for wts in mask_model_lenet_stripped.trainable_weights:\n",
    "    wts.assign(tf.where(tf.equal(wts, 0.), 0., 1.))\n",
    "\n",
    "## these tensoflow functions have to be defined again before usage everytime\n",
    "## also the optimizers and loss function has to be reinitialized to reset them\n",
    "\n",
    "# Choose an optimizer and loss function for training-\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(0.0012)\n",
    "\n",
    "# Select metrics to measure the error and the accuracy of the model.\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name = 'train_accuracy')\n",
    "\n",
    "val_loss = tf.keras.metrics.Mean(name = 'val_loss')\n",
    "val_accuracy = tf.keras.metrics.CategoricalAccuracy(name = 'val_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name = 'test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name = 'test_accuracy')\n",
    "\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_one_step(model, mask_model, optimizer, x, y):\n",
    "    '''\n",
    "    def train_step(data, labels):\n",
    "    Function to compute one step of gradient descent optimization\n",
    "    '''\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Make predictions using defined model-\n",
    "        y_pred = model(x)\n",
    "\n",
    "        # Compute loss-\n",
    "        loss = loss_fn(y, y_pred)\n",
    "\n",
    "    # Compute gradients wrt defined loss and weights and biases-\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # List to hold element-wise multiplication between-\n",
    "    # computed gradient and masks-\n",
    "    grad_mask_mul = []\n",
    "\n",
    "    # Perform element-wise multiplication between computed gradients and masks-\n",
    "    for grad_layer, mask in zip(grads, mask_model.trainable_weights):\n",
    "        grad_mask_mul.append(tf.math.multiply(grad_layer, mask))\n",
    "\n",
    "    # Apply computed gradients to model's weights and biases-\n",
    "    # optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    # normally we just apply the grads but here we use masked grads\n",
    "    optimizer.apply_gradients(zip(grad_mask_mul, model.trainable_variables))\n",
    "\n",
    "    # Compute loss and accuracy-\n",
    "    train_loss(loss)\n",
    "    train_accuracy(y, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def val_step(model, optimizer, data, labels):\n",
    "    \"\"\"\n",
    "    Function to val model performance\n",
    "    on validation dataset\n",
    "    \"\"\"\n",
    "\n",
    "    predictions = model(data)\n",
    "    t_loss = loss_fn(labels, predictions)\n",
    "\n",
    "    val_loss(t_loss)\n",
    "    val_accuracy(labels, predictions)\n",
    "\n",
    "@tf.function\n",
    "def test_step(model, optimizer, data, labels):\n",
    "    \"\"\"\n",
    "    Function to test model performance\n",
    "    on testing dataset\n",
    "    \"\"\"\n",
    "\n",
    "    predictions = model(data)\n",
    "    t_loss = loss_fn(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)\n",
    "\n",
    "\n",
    "patience_val = np.zeros(patience)\n",
    "\n",
    "#min_loss and patience_sofar is the variables to manually enable early stopping  \n",
    "\n",
    "min_loss=10\n",
    "patience_sofar=0\n",
    "\n",
    "# these metrics are to enable calculations in every 100 iterations\n",
    "hunderd_iter=[i*100-1 for i in range(1,11)]\n",
    "iteration=0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    #to stop training when earlystopping criterion met\n",
    "    if patience_sofar >= patience:\n",
    "        print(\"\\n\\nEarlyStopping Evoked! Stopping training\\n\\n\")\n",
    "        break\n",
    "\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    #val_loss.reset_states()\n",
    "    #val_accuracy.reset_states()\n",
    "\n",
    "    for i, (x,y) in enumerate(train_dataset):\n",
    "        train_one_step(lenet_model_stripped, mask_model_lenet_stripped, optimizer, x, y)\n",
    "        if i in hunderd_iter:\n",
    "            val_loss.reset_states()\n",
    "            val_accuracy.reset_states()\n",
    "            for x_t, y_t in val_dataset:\n",
    "                val_step(lenet_model_stripped, optimizer, x_t, y_t)\n",
    "            history_lenet_batch['accuracy'][iteration] = train_accuracy.result()\n",
    "            history_lenet_batch['loss'][iteration] = train_loss.result()\n",
    "            history_lenet_batch['val_loss'][iteration] = val_loss.result()\n",
    "            history_lenet_batch['val_accuracy'][iteration] = val_accuracy.result()\n",
    "            #we are saving the weights in every 100 iteration. So that we can load the weights of the minimum validation\n",
    "            #loss and evaluate the test accuracy on the test set\n",
    "            lenet_model_stripped.save_weights(\"{}/Lenet_300_100_Trained_weights_iter_{}.h5\".format(orig_dirname,iteration),\n",
    "                                              overwrite=True)\n",
    "\n",
    "            iteration+=1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "\n",
    "#    for x_t, y_t in val_dataset:\n",
    "#        val_step(lenet_model_stripped, optimizer, x_t, y_t)\n",
    "\n",
    "\n",
    "    #Printing the results after every epoch\n",
    "    template = 'Epoch {0}, Loss: {1:.4f}, Accuracy: {2:.4f}, val Loss: {3:.4f}, val Accuracy: {4:4f}'\n",
    "\n",
    "    history_lenet['accuracy'][epoch] = train_accuracy.result()\n",
    "    history_lenet['loss'][epoch] = train_loss.result()\n",
    "    history_lenet['val_loss'][epoch] = val_loss.result()\n",
    "    history_lenet['val_accuracy'][epoch] = val_accuracy.result()\n",
    "\n",
    "    print(template.format(epoch + 1, \n",
    "                          train_loss.result(), train_accuracy.result()*100,\n",
    "                          val_loss.result(), val_accuracy.result()*100))\n",
    "\n",
    "    # Count number of non-zero parameters in each layer and in total-\n",
    "\n",
    "    model_sum_params = 0\n",
    "\n",
    "    for layer in lenet_model_stripped.trainable_weights:\n",
    "\n",
    "        model_sum_params += tf.math.count_nonzero(layer, axis = None).numpy()\n",
    "\n",
    "    print(\"Total number of trainable parameters = {0}\\n\".format(model_sum_params))\n",
    "\n",
    "    #for computing the early stopping manually\n",
    "\n",
    "    if (min_loss-history_lenet['val_loss'][epoch])>minimum_delta:\n",
    "        min_loss=history_lenet['val_loss'][epoch]\n",
    "    else:\n",
    "        patience_sofar+=1\n",
    "\n",
    "\n",
    "\n",
    "#to clear the zero values from dictionary to have better visualization\n",
    "\n",
    "for metrics in history_lenet.keys():\n",
    "        history_lenet[metrics] = np.resize(history_lenet[metrics], new_shape = epoch)\n",
    "for metrics in history_lenet_batch.keys():\n",
    "        history_lenet_batch[metrics] = np.resize(history_lenet_batch[metrics], new_shape = iteration)\n",
    "\n",
    "# Evaluating the minimum validation loss and the corresponding accuracy  after the training\n",
    "min_val_loss_iter=np.argmin(history_lenet_batch['val_loss'])\n",
    "history_lenet_batch['min_iter']=int(min_val_loss_iter)\n",
    "\n",
    "#we are getting the weights in the minimum validation loss\n",
    "lenet_model_stripped.load_weights(\"{}/Lenet_300_100_Trained_weights_iter_{}.h5\".format(orig_dirname,min_val_loss_iter))\n",
    "\n",
    "#calculating the test accuracy\n",
    "test_accuracy.reset_states()\n",
    "for x_t, y_t in test_dataset:\n",
    "    test_step(lenet_model_stripped, optimizer, x_t, y_t)\n",
    "history_lenet_batch['test_accuracy']=float(test_accuracy.result())\n",
    "\n",
    "print('Training of the original Lenet 300-100 is finished.')\n",
    "\n",
    "#Experiment loop for the smaller networks starts here\n",
    "\n",
    "print('Experiment for the smaller network sizes begins...')\n",
    "\n",
    "for (first_layer,second_layer) in layers_model:\n",
    "    print(first_layer,second_layer)\n",
    "\n",
    "    # Instantiate random the NN-\n",
    "    orig_model = pruned_nn(pruning_params_unpruned,first_layer=first_layer,second_layer=second_layer)\n",
    "\n",
    "    # Save random initialized weights BEFORE pruning and training of NN\n",
    "    # and BEFORE the model is STRIPPED-\n",
    "\n",
    "    #first let's create the folder\n",
    "    \n",
    "    #actually we dont have to use different folders for the strategies. So it can be modified.\n",
    "    dirName='Exp_Strategy_{}'.format(strategy)\n",
    "\n",
    "    if not os.path.exists(dirName):\n",
    "        os.mkdir(dirName)\n",
    "        print(\"Directory \" , dirName ,  \" Created \")\n",
    "    else:    \n",
    "        print(\"Directory \" , dirName ,  \" already exists\")\n",
    "\n",
    "    orig_model.save_weights(\"{}/MNIST_{}_{}_Randomly_Initialized_weights.h5\".format(dirName,first_layer,second_layer), overwrite=True)\n",
    "\n",
    "    # Strip the pruning wrappers from UNPRUNED model-\n",
    "    orig_model_stripped = sparsity.strip_pruning(orig_model)\n",
    "\n",
    "\n",
    "    # Save random uninitialized weights BEFORE pruning of NN using STRIPPED model-\n",
    "    orig_model_stripped.save_weights(\"{}/MNIST_{}_{}_Randomly_Initialized_weights_stripped.h5\".format(dirName,first_layer,second_layer)\n",
    "                                     , overwrite=True)\n",
    "\n",
    "    #these functions calculates the parameters in the network\n",
    "    orig_model_params=parameter_count('orig_model',orig_model)\n",
    "\n",
    "    orig_model_stripped_params=parameter_count('orig_model_stripped',orig_model_stripped)\n",
    "\n",
    "    print('orig model summary:')\n",
    "    orig_model_stripped.summary()\n",
    "\n",
    "    ## Funtion that computes the Iterative Pruning Rounds based on the pruning rate and the target sparsity\n",
    "\n",
    "\n",
    "    prun_rates,num_prun_rounds=pruning_rounds(orig_model_stripped,pruning_percentage=pruning_percentage,target=target)\n",
    "\n",
    "    ### Lets create a dictionary for the history of the models\n",
    "\n",
    "    #one for the epochs\n",
    "    # one for the batches\n",
    "\n",
    "\n",
    "    \n",
    "    history_main = {}\n",
    "\n",
    "    \n",
    "    for x in range(num_prun_rounds):\n",
    "        history = {}\n",
    "\n",
    "        # Neural Network model, scalar metrics-\n",
    "        history['accuracy'] = np.zeros(shape = epochs)\n",
    "        history['val_accuracy'] = np.zeros(shape = epochs)\n",
    "        history['loss'] = np.zeros(shape = epochs)\n",
    "        history['val_loss'] = np.zeros(shape = epochs)\n",
    "\n",
    "        # compute % of weights pruned at the end of each iterative pruning round-\n",
    "        history['percentage_wts_pruned'] = 0\n",
    "        history['units_first_layer'] = first_layer\n",
    "        history['units_second_layer'] = second_layer\n",
    "        history['strategy'] = strategy\n",
    "        history['patience'] = patience\n",
    "        history['pruning_rate'] = pruning_percentage\n",
    "\n",
    "        history_main[x + 1] = history\n",
    "\n",
    "\n",
    "\n",
    "    history_main_batch = {}\n",
    "\n",
    "    \n",
    "    for x in range(num_prun_rounds):\n",
    "        history = {}\n",
    "\n",
    "        # Neural Network model, scalar metrics-\n",
    "        history['accuracy'] = np.zeros(shape = epochs*10)\n",
    "        history['val_accuracy'] = np.zeros(shape = epochs*10)\n",
    "        history['loss'] = np.zeros(shape = epochs*10)\n",
    "        history['val_loss'] = np.zeros(shape = epochs*10)\n",
    "\n",
    "        # compute % of weights pruned at the end of each iterative pruning round-\n",
    "        history['percentage_wts_pruned'] = 0\n",
    "        history['units_first_layer'] = first_layer\n",
    "        history['units_second_layer'] = second_layer\n",
    "        history['strategy'] = strategy\n",
    "        history['patience'] = patience\n",
    "        history['pruning_rate'] = pruning_percentage\n",
    "\n",
    "        history_main_batch[x + 1] = history\n",
    "\n",
    "\n",
    "    ### 2: Train the unpruned Network until it converges\n",
    "\n",
    "    #We will also use Gradient Tape here to be consistent with the Winning Ticket model\n",
    "\n",
    "    #Early Stopping criterion has been used for training of the model\n",
    "\n",
    "\n",
    "    ##these tensoflow functions have to be defined again before usage everytime\n",
    "    # Choose an optimizer and loss function for training-\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "    optimizer = tf.keras.optimizers.Adam(0.0012)\n",
    "\n",
    "    # Select metrics to measure the error & accuracy of model.\n",
    "    # These metrics accumulate the values over epochs and then\n",
    "    # print the overall result-\n",
    "    train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n",
    "    train_accuracy = tf.keras.metrics.CategoricalAccuracy(name = 'train_accuracy')\n",
    "\n",
    "    val_loss = tf.keras.metrics.Mean(name = 'val_loss')\n",
    "    val_accuracy = tf.keras.metrics.CategoricalAccuracy(name = 'val_accuracy')\n",
    "\n",
    "    test_loss = tf.keras.metrics.Mean(name = 'test_loss')\n",
    "    test_accuracy = tf.keras.metrics.CategoricalAccuracy(name = 'test_accuracy')\n",
    "\n",
    "    @tf.function\n",
    "    def train_one_step(model, mask_model, optimizer, x, y):\n",
    "        '''\n",
    "        def train_step(data, labels):\n",
    "        Function to compute one step of gradient descent optimization\n",
    "        '''\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Make predictions using defined model-\n",
    "            y_pred = model(x)\n",
    "\n",
    "            # Compute loss-\n",
    "            loss = loss_fn(y, y_pred)\n",
    "\n",
    "        # Compute gradients wrt defined loss and weights and biases-\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "        # List to hold element-wise multiplication between-\n",
    "        # computed gradient and masks-\n",
    "        grad_mask_mul = []\n",
    "\n",
    "        # Perform element-wise multiplication between computed gradients and masks-\n",
    "        for grad_layer, mask in zip(grads, mask_model.trainable_weights):\n",
    "            grad_mask_mul.append(tf.math.multiply(grad_layer, mask))\n",
    "\n",
    "        # Apply computed gradients to model's weights and biases-\n",
    "        # optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        # normally we just apply the grads but here we use masked grads\n",
    "        optimizer.apply_gradients(zip(grad_mask_mul, model.trainable_variables))\n",
    "\n",
    "        # Compute accuracy-\n",
    "        train_loss(loss)\n",
    "        train_accuracy(y, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def val_step(model, optimizer, data, labels):\n",
    "        \"\"\"\n",
    "        Function to val model performance\n",
    "        on validation dataset\n",
    "        \"\"\"\n",
    "\n",
    "        predictions = model(data)\n",
    "        t_loss = loss_fn(labels, predictions)\n",
    "\n",
    "        val_loss(t_loss)\n",
    "        val_accuracy(labels, predictions)\n",
    "\n",
    "    @tf.function\n",
    "    def test_step(model, optimizer, data, labels):\n",
    "        \"\"\"\n",
    "        Function to test model performance\n",
    "        on testing dataset\n",
    "        \"\"\"\n",
    "\n",
    "        predictions = model(data)\n",
    "        t_loss = loss_fn(labels, predictions)\n",
    "\n",
    "        test_loss(t_loss)\n",
    "        test_accuracy(labels, predictions)\n",
    "\n",
    "\n",
    "    \n",
    "    # Instantiate a new neural network model for which, the mask is to be created,\n",
    "\n",
    "    mask_model_orig = pruned_nn(pruning_params_unpruned,first_layer,second_layer)\n",
    "\n",
    "    # Load weights of PRUNED model-\n",
    "    mask_model_orig.load_weights(\"{}/MNIST_{}_{}_Randomly_Initialized_weights.h5\".format(dirName,first_layer,second_layer))\n",
    "\n",
    "    # Strip the model of its pruning parameters-\n",
    "    mask_model_orig_stripped = sparsity.strip_pruning(mask_model_orig)\n",
    "\n",
    "    #for the original models as well we create mask with zeros because there will be no pruning\n",
    "\n",
    "    for wts in mask_model_orig_stripped.trainable_weights:\n",
    "        wts.assign(tf.where(tf.equal(wts, 0.), 0., 1.))\n",
    "\n",
    "    # Dictionary to hold scalar metrics-\n",
    "    history_orig = {}\n",
    "\n",
    "    history_orig['accuracy'] = np.zeros(epochs)\n",
    "    history_orig['val_accuracy'] = np.zeros(epochs)\n",
    "    history_orig['loss'] = np.zeros(epochs)\n",
    "    history_orig['val_loss'] = np.zeros(epochs)\n",
    "    history_orig['percentage_wts_pruned'] = 0\n",
    "    history_orig['units_first_layer'] = first_layer\n",
    "    history_orig['units_second_layer'] = second_layer\n",
    "    history_orig['strategy'] = strategy\n",
    "    history_orig['patience'] = patience\n",
    "    history_orig['pruning_rate'] = pruning_percentage\n",
    "\n",
    "    # Dictionary to hold scalar metrics-\n",
    "    history_orig_batch = {}\n",
    "\n",
    "    history_orig_batch['accuracy'] = np.zeros(epochs*10)\n",
    "    history_orig_batch['val_accuracy'] = np.zeros(epochs*10)\n",
    "    history_orig_batch['loss'] = np.zeros(epochs*10)\n",
    "    history_orig_batch['val_loss'] = np.zeros(epochs*10)\n",
    "    history_orig_batch['percentage_wts_pruned'] = 0\n",
    "    history_orig_batch['units_first_layer'] = first_layer\n",
    "    history_orig_batch['units_second_layer'] = second_layer\n",
    "    history_orig_batch['strategy'] = strategy\n",
    "    history_orig_batch['patience'] = patience\n",
    "    history_orig_batch['pruning_rate'] = pruning_percentage\n",
    "\n",
    "\n",
    "    patience_val = np.zeros(patience)\n",
    "\n",
    "    #min_loss and patience_sofar is the variables to manually enable early stopping  \n",
    "\n",
    "    min_loss=10\n",
    "    patience_sofar=0\n",
    "    #To enable the saving the validation loss in every 100 iteration\n",
    "    hunderd_iter=[i*100-1 for i in range(1,11)]\n",
    "    iteration=0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        #to stop training when earlystopping criterion met\n",
    "        if patience_sofar >= patience:\n",
    "            print(\"\\n\\nEarlyStopping Evoked! Stopping training\\n\\n\")\n",
    "            break\n",
    "\n",
    "        # Reset the metrics at the start of the next epoch\n",
    "        train_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "        #val_loss.reset_states()\n",
    "        #val_accuracy.reset_states()\n",
    "\n",
    "        for i, (x,y) in enumerate(train_dataset):\n",
    "            train_one_step(orig_model_stripped, mask_model_orig_stripped, optimizer, x, y)\n",
    "            if i in hunderd_iter:\n",
    "                val_loss.reset_states()\n",
    "                val_accuracy.reset_states()\n",
    "                for x_t, y_t in val_dataset:\n",
    "                    val_step(orig_model_stripped, optimizer, x_t, y_t)\n",
    "                history_orig_batch['accuracy'][iteration] = train_accuracy.result()\n",
    "                history_orig_batch['loss'][iteration] = train_loss.result()\n",
    "                history_orig_batch['val_loss'][iteration] = val_loss.result()\n",
    "                history_orig_batch['val_accuracy'][iteration] = val_accuracy.result()\n",
    "                #Saving the weights of the model in every 100 iteration. So that we can use the weights of the minimum\n",
    "                #validation loss model to evaluate corresponding test accuracy after the training\n",
    "                orig_model.save_weights(\"{}/MNIST_{}_{}_Trained_Weights_Unpruned_iter_{}.h5\".format(dirName,first_layer,second_layer,iteration),\n",
    "                            overwrite = True)\n",
    "\n",
    "                iteration+=1\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "\n",
    "    #    for x_t, y_t in val_dataset:\n",
    "    #        val_step(orig_model_stripped, optimizer, x_t, y_t)\n",
    "\n",
    "\n",
    "        #printing the results after every epoch\n",
    "        template = 'Epoch {0}, Loss: {1:.4f}, Accuracy: {2:.4f}, val Loss: {3:.4f}, val Accuracy: {4:4f}'\n",
    "\n",
    "        history_orig['accuracy'][epoch] = train_accuracy.result()\n",
    "        history_orig['loss'][epoch] = train_loss.result()\n",
    "        history_orig['val_loss'][epoch] = val_loss.result()\n",
    "        history_orig['val_accuracy'][epoch] = val_accuracy.result()\n",
    "\n",
    "        print(template.format(epoch + 1, \n",
    "                              train_loss.result(), train_accuracy.result()*100,\n",
    "                              val_loss.result(), val_accuracy.result()*100))\n",
    "\n",
    "        # Count number of non-zero parameters in each layer and in total-\n",
    "\n",
    "        model_sum_params = 0\n",
    "\n",
    "        for layer in orig_model_stripped.trainable_weights:\n",
    "\n",
    "            model_sum_params += tf.math.count_nonzero(layer, axis = None).numpy()\n",
    "\n",
    "        print(\"Total number of trainable parameters = {0}\\n\".format(model_sum_params))\n",
    "\n",
    "        #for computing the early stopping manually\n",
    "\n",
    "        if (min_loss-history_orig['val_loss'][epoch])>minimum_delta:\n",
    "            min_loss=history_orig['val_loss'][epoch]\n",
    "        else:\n",
    "            patience_sofar+=1\n",
    "\n",
    "\n",
    "\n",
    "    #to clear the zero values from dictionary to have better visualization\n",
    "\n",
    "\n",
    "    for metrics in history_orig.keys():\n",
    "            history_orig[metrics] = np.resize(history_orig[metrics], new_shape = epoch)\n",
    "    for metrics in history_orig_batch.keys():\n",
    "            history_orig_batch[metrics] = np.resize(history_orig_batch[metrics], new_shape = iteration)\n",
    "\n",
    "    #for k,v in history_orig.items():\n",
    "    #    history_orig[k]=np.where(v==0,np.nan,v)\n",
    "    min_val_loss_iter=np.argmin(history_orig_batch['val_loss'])\n",
    "    history_orig_batch['min_iter']=int(min_val_loss_iter)\n",
    "\n",
    "    #we are getting the weights in the minimum validation loss\n",
    "    orig_model.load_weights(\"{}/MNIST_{}_{}_Trained_Weights_Unpruned_iter_{}.h5\".format(dirName,first_layer,second_layer,min_val_loss_iter))\n",
    "\n",
    "    #calculating the test accuracy\n",
    "    test_accuracy.reset_states()\n",
    "    for x_t, y_t in test_dataset:\n",
    "        test_step(orig_model_stripped, optimizer, x_t, y_t)\n",
    "    history_orig_batch['test_accuracy']=float(test_accuracy.result())\n",
    "\n",
    "\n",
    "    # We are saving the weights at the minimum validation loss to make pruning in next steps\n",
    "    orig_model.save_weights(\"{}/MNIST_{}_{}_Trained_Weights_Unpruned.h5\".format(dirName,first_layer,second_layer),\n",
    "                            overwrite = True)\n",
    "\n",
    "    # Here our iterative pruning loop start\n",
    "\n",
    "    for i in range(len(prun_rates)):\n",
    "\n",
    "        # we need to set the epoch again to inital value\n",
    "        epoch=50\n",
    "\n",
    "        #Based on the strategy selected, different pruning strategies will be used\n",
    "        if strategy==1:\n",
    "            print(\"strategy 1 is selected\")\n",
    "        # Instantiate a Neureal Network model to be pruned using parameters from above-\n",
    "            pruned_model = pruned_nn(pruning_params_unpruned,first_layer,second_layer)\n",
    "\n",
    "            \n",
    "            #Loading the weights to be pruned.\n",
    "            pruned_model.load_weights(\"{}/MNIST_{}_{}_Trained_Weights_Unpruned.h5\".format(dirName,first_layer,second_layer))\n",
    "\n",
    "            # Strip the pruning wrappers from pruned model-\n",
    "            pruned_model_stripped = sparsity.strip_pruning(pruned_model)\n",
    "\n",
    "            # Prun the weights\n",
    "            prune_network(pruned_model_stripped,pruning_percentage=prun_rates[i])\n",
    "\n",
    "            # Save weights of PRUNED and Trained model BEFORE stripping-\n",
    "            pruned_model.save_weights(\"{}/MNIST_{}_{}_Weights_Pruned.h5\".format(dirName,first_layer,second_layer), overwrite = True)\n",
    "\n",
    "        else:\n",
    "            print('strategy 2 is selected')\n",
    "            pruning_params_pruned = define_pruning_params(target=prun_rates[i],end=-1)\n",
    "\n",
    "            # Instantiate a Neureal Network model to be pruned using parameters from above-\n",
    "            pruned_model = pruned_nn(pruning_params_pruned,first_layer,second_layer)\n",
    "\n",
    "            \n",
    "            #Loading the weights to be pruned\n",
    "            pruned_model.load_weights(\"{}/MNIST_{}_{}_Trained_Weights_Unpruned.h5\".format(dirName,first_layer,second_layer))\n",
    "\n",
    "            # Train the NN to be pruned\n",
    "            history_pruned = pruned_model.fit(\n",
    "                x = X_train, y = y_train,\n",
    "                batch_size = batch_size,\n",
    "                epochs = 4, #since the model is already trained, TF website advises to train only for 4 epochs\n",
    "                verbose = 1,\n",
    "                callbacks=callbacks,\n",
    "                #validation_data = (X_val, y_val),\n",
    "                shuffle = True\n",
    "            )\n",
    "\n",
    "\n",
    "            # Save weights of PRUNED and Trained model BEFORE stripping-\n",
    "            pruned_model.save_weights(\"{}/MNIST_{}_{}_Weights_Pruned.h5\".format(dirName,first_layer,second_layer), overwrite = True)\n",
    "\n",
    "            # Strip the pruning wrappers from pruned model-\n",
    "            pruned_model_stripped = sparsity.strip_pruning(pruned_model)\n",
    "\n",
    "\n",
    "        # we need to load the original weights to the model before we continue\n",
    "        #because we need to reset the weights to their initial values\n",
    "\n",
    "        orig_model_stripped.load_weights(\"{}/MNIST_{}_{}_Randomly_Initialized_weights_stripped.h5\".format(dirName,first_layer,second_layer))\n",
    "\n",
    "        # Sanity-check: confirm that p = 30% of the weights are actually pruned away from the network-\n",
    "\n",
    "        #we are subtracting 410 because it is the number of the units in the neural net\n",
    "        orig_model_stripped_params=parameter_count('orig_model_stripped',orig_model_stripped,verbose=0)\n",
    "        pruned_model_params=parameter_count('pruned_model',pruned_model,verbose=0)\n",
    "\n",
    "        print(\"\\n% of weights pruned away = {0:.2f}%\\n\".format( \\\n",
    "            (orig_model_stripped_params - pruned_model_params) / orig_model_stripped_params * 100))\n",
    "        history_main[i+1]['percentage_wts_pruned']=np.round((orig_model_stripped_params - pruned_model_params) / orig_model_stripped_params * 100,2)\n",
    "        history_main_batch[i+1]['percentage_wts_pruned']=np.round((orig_model_stripped_params - pruned_model_params) / orig_model_stripped_params * 100,2)\n",
    "\n",
    "        # Instantiate a new neural network model for which, the mask is to be created,\n",
    "\n",
    "        mask_model = pruned_nn(pruning_params_unpruned,first_layer,second_layer)\n",
    "\n",
    "        # Load weights of PRUNED model-\n",
    "        mask_model.load_weights(\"{}/MNIST_{}_{}_Weights_Pruned.h5\".format(dirName,first_layer,second_layer))\n",
    "\n",
    "        # Strip the model of its pruning parameters-\n",
    "        mask_model_stripped = sparsity.strip_pruning(mask_model)\n",
    "\n",
    "        # For each layer, for each weight which is 0, leave it, as is.\n",
    "        # And for weights which survive the pruning,reinitialize it to ONE (1)-\n",
    "\n",
    "        for wts in mask_model_stripped.trainable_weights:\n",
    "            wts.assign(tf.where(tf.equal(wts, 0.), 0., 1.))\n",
    "\n",
    "        mask_model_stripped_params=parameter_count('mask_model_stripped',mask_model_stripped,verbose=0)\n",
    "\n",
    "        # Instantiate a new neural network model for which, the weights are to be extracted\n",
    "\n",
    "        winning_ticket_model = pruned_nn(pruning_params_unpruned,first_layer,second_layer)\n",
    "\n",
    "        # Load weights of PRUNED model-\n",
    "\n",
    "        winning_ticket_model.load_weights(\"{}/MNIST_{}_{}_Weights_Pruned.h5\".format(dirName,first_layer,second_layer))\n",
    "\n",
    "        # Strip the model of its pruning parameters-\n",
    "\n",
    "        winning_ticket_model_stripped = sparsity.strip_pruning(winning_ticket_model)\n",
    "\n",
    "        # For each layer, for each weight which is 0, leave it, as is. And for weights which survive the pruning,\n",
    "        # reinitialize it to the value, the model received BEFORE it was trained and pruned-\n",
    "\n",
    "        for orig_wts, pruned_wts in zip(orig_model_stripped.trainable_weights, winning_ticket_model_stripped.trainable_weights):\n",
    "            pruned_wts.assign(tf.where(tf.equal(pruned_wts, 0), pruned_wts, orig_wts))\n",
    "\n",
    "        winning_ticket_stripped_params=parameter_count('winning_ticket_model_stripped',winning_ticket_model_stripped,verbose=0)\n",
    "\n",
    "        \n",
    "        # Save the weights (with pruning parameters) extracted to a file-\n",
    "\n",
    "        winning_ticket_model_stripped.save_weights(\"{}/MNIST_{}_{}_Winning_Ticket.h5\".format(dirName,first_layer,second_layer), overwrite=True)\n",
    "\n",
    "        #Instantiate a model for iterative pruning-\n",
    "        model_gt = pruned_nn(pruning_params_unpruned,first_layer,second_layer)\n",
    "\n",
    "        model_gt_stripped=sparsity.strip_pruning(model_gt)\n",
    "\n",
    "        # Load weights of winning ticket-\n",
    "        model_gt_stripped.load_weights(\"{}/MNIST_{}_{}_Winning_Ticket.h5\".format(dirName,first_layer,second_layer))\n",
    "        \n",
    "        #printing to see where are we at the training actually.\n",
    "        #it is not necessary\n",
    "        print(model_gt_stripped.summary())\n",
    "\n",
    "        # Choose an optimizer and loss function for training-\n",
    "        loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "        optimizer = tf.keras.optimizers.Adam(0.0012)\n",
    "\n",
    "        # Select metrics to measure the error & accuracy of model.\n",
    "        train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n",
    "        train_accuracy = tf.keras.metrics.CategoricalAccuracy(name = 'train_accuracy')\n",
    "\n",
    "        val_loss = tf.keras.metrics.Mean(name = 'val_loss')\n",
    "        val_accuracy = tf.keras.metrics.CategoricalAccuracy(name = 'val_accuracy')\n",
    "\n",
    "        test_loss = tf.keras.metrics.Mean(name = 'test_loss')\n",
    "        test_accuracy = tf.keras.metrics.CategoricalAccuracy(name = 'test_accuracy')\n",
    "\n",
    "\n",
    "        @tf.function\n",
    "        def train_one_step(model, mask_model, optimizer, x, y):\n",
    "            '''\n",
    "            def train_step(data, labels):\n",
    "            Function to compute one step of gradient descent optimization\n",
    "            '''\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Make predictions using defined model-\n",
    "                y_pred = model(x)\n",
    "\n",
    "                # Compute loss-\n",
    "                loss = loss_fn(y, y_pred)\n",
    "\n",
    "            # Compute gradients wrt defined loss and weights and biases-\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "            \n",
    "            # List to hold element-wise multiplication between-\n",
    "            # computed gradient and masks-\n",
    "            grad_mask_mul = []\n",
    "\n",
    "            # Perform element-wise multiplication between computed gradients and masks-\n",
    "            for grad_layer, mask in zip(grads, mask_model.trainable_weights):\n",
    "                grad_mask_mul.append(tf.math.multiply(grad_layer, mask))\n",
    "\n",
    "            # Apply computed gradients to model's weights and biases-\n",
    "            # optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            # normally we just apply the grads but here we use masked grads\n",
    "            optimizer.apply_gradients(zip(grad_mask_mul, model.trainable_variables))\n",
    "\n",
    "            # Compute accuracy-\n",
    "            train_loss(loss)\n",
    "            train_accuracy(y, y_pred)\n",
    "\n",
    "            \n",
    "\n",
    "        @tf.function\n",
    "        def val_step(model, optimizer, data, labels):\n",
    "            \"\"\"\n",
    "            Function to val model performance\n",
    "            on valing dataset\n",
    "            \"\"\"\n",
    "\n",
    "            predictions = model(data)\n",
    "            t_loss = loss_fn(labels, predictions)\n",
    "\n",
    "            val_loss(t_loss)\n",
    "            val_accuracy(labels, predictions)\n",
    "\n",
    "        @tf.function\n",
    "        def test_step(model, optimizer, data, labels):\n",
    "            \"\"\"\n",
    "            Function to test model performance\n",
    "            on testing dataset\n",
    "            \"\"\"\n",
    "\n",
    "            predictions = model(data)\n",
    "            t_loss = loss_fn(labels, predictions)\n",
    "\n",
    "            test_loss(t_loss)\n",
    "            test_accuracy(labels, predictions)\n",
    "\n",
    "        ### Provide parameters for _EarlyStopping_\n",
    "\n",
    "        #The parameters should be same with the original model\n",
    "\n",
    "\n",
    "        patience_val = np.zeros(patience)\n",
    "\n",
    "        #min_loss and patience_sofar is the variables to manually enable early stopping  \n",
    "\n",
    "        min_loss=10\n",
    "        patience_sofar=0\n",
    "\n",
    "        #this is calculated to evaluate the validation loss in every 100 iterations\n",
    "        hunderd_iter=[i*100-1 for i in range(1,11)]\n",
    "        iteration=0\n",
    "\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            #to stop training when earlystopping criterion met\n",
    "            if patience_sofar >= patience:\n",
    "                print(\"\\n\\nEarlyStopping Evoked! Stopping training\\n\\n\")\n",
    "                break\n",
    "\n",
    "            # Reset the metrics at the start of the next epoch\n",
    "            train_loss.reset_states()\n",
    "            train_accuracy.reset_states()\n",
    "            #val_loss.reset_states()\n",
    "            #val_accuracy.reset_states()\n",
    "\n",
    "            for j, (x,y) in enumerate(train_dataset):\n",
    "                train_one_step(model_gt_stripped, mask_model_stripped, optimizer, x, y)\n",
    "                if j in hunderd_iter:\n",
    "                    val_loss.reset_states()\n",
    "                    val_accuracy.reset_states()\n",
    "                    for x_t, y_t in val_dataset:\n",
    "                        val_step(model_gt_stripped, optimizer, x_t, y_t)\n",
    "                    history_main_batch[i+1]['accuracy'][iteration] = train_accuracy.result()\n",
    "                    history_main_batch[i+1]['loss'][iteration] = train_loss.result()\n",
    "                    history_main_batch[i+1]['val_loss'][iteration] = val_loss.result()\n",
    "                    history_main_batch[i+1]['val_accuracy'][iteration] = val_accuracy.result()\n",
    "                    #Saving the weights in every 100 iterations again.\n",
    "                    model_gt.save_weights(\"{}/MNIST_{}_{}_Trained_Weights_gt_Unpruned_iter_{}.h5\".format(dirName,first_layer,second_layer,iteration), overwrite=True)\n",
    "                    iteration+=1\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "\n",
    "    #        for x_t, y_t in val_dataset:\n",
    "\n",
    "     #           val_step(model_gt_stripped, optimizer, x_t, y_t)\n",
    "            #for printing the results after every epoch\n",
    "            template = 'Epoch {0}, Loss: {1:.4f}, Accuracy: {2:.4f}, val Loss: {3:.4f}, val Accuracy: {4:4f}'\n",
    "\n",
    "            history_main[i+1]['accuracy'][epoch] = train_accuracy.result()\n",
    "            history_main[i+1]['loss'][epoch] = train_loss.result()\n",
    "            history_main[i+1]['val_loss'][epoch] = val_loss.result()\n",
    "            history_main[i+1]['val_accuracy'][epoch] = val_accuracy.result()\n",
    "\n",
    "            print(template.format(epoch + 1, \n",
    "                                  train_loss.result(), train_accuracy.result()*100,\n",
    "                                  val_loss.result(), val_accuracy.result()*100))\n",
    "\n",
    "            # Count number of non-zero parameters in each layer and in total-\n",
    "\n",
    "            model_sum_params = 0\n",
    "\n",
    "            for layer in model_gt_stripped.trainable_weights:\n",
    "\n",
    "                model_sum_params += tf.math.count_nonzero(layer, axis = None).numpy()\n",
    "\n",
    "            print(\"Total number of trainable parameters = {0}\\n\".format(model_sum_params))\n",
    "\n",
    "            #for computing the early stopping manually\n",
    "\n",
    "            if (min_loss-history_main[i+1]['val_loss'][epoch])>minimum_delta:\n",
    "                min_loss=history_main[i+1]['val_loss'][epoch]\n",
    "            else:\n",
    "                patience_sofar+=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #to clean the zero values from the dictionary\n",
    "\n",
    "        for metrics in history_main[i+1].keys():\n",
    "            history_main[i+1][metrics] = np.resize(history_main[i+1][metrics], new_shape = epoch)\n",
    "        for metrics in history_main_batch[i+1].keys():\n",
    "            history_main_batch[i+1][metrics] = np.resize(history_main_batch\n",
    "                                                         [i+1][metrics], new_shape = iteration)\n",
    "\n",
    "        min_val_loss_iter=np.argmin(history_main_batch[i+1]['val_loss'])\n",
    "        history_main_batch[i+1]['min_iter']=int(min_val_loss_iter)\n",
    "\n",
    "        #we are getting the weights in the minimum validation loss\n",
    "        model_gt.load_weights(\"{}/MNIST_{}_{}_Trained_Weights_gt_Unpruned_iter_{}.h5\".format(dirName,first_layer,second_layer,min_val_loss_iter))\n",
    "\n",
    "        #calculating the test accuracy\n",
    "        test_accuracy.reset_states()\n",
    "        for x_t, y_t in test_dataset:\n",
    "            test_step(model_gt_stripped, optimizer, x_t, y_t)\n",
    "        history_main_batch[i+1]['test_accuracy']=float(test_accuracy.result())\n",
    "\n",
    "\n",
    "        # Save weights of Winning Ticket (One Shot) trained with GradientTape WITH pruning parameters-\n",
    "        model_gt.save_weights(\"{}/MNIST_{}_{}_Trained_Weights_Unpruned.h5\".format(dirName,first_layer,second_layer), overwrite=True)\n",
    "\n",
    "    ## lets check if there is actually winning tickets or not\n",
    "\n",
    "\n",
    "    wt=0\n",
    "    swt=0\n",
    "    for i in range(1,len(prun_rates)+1):\n",
    "        print('percentage pruned:{:.3f}'.format(history_main[i]['percentage_wts_pruned'][0]))\n",
    "        orig_val_loss=min(history_orig_batch['val_loss'])\n",
    "        round_orig=history_orig_batch['min_iter']\n",
    "        acc_orig=history_orig_batch['test_accuracy']\n",
    "        lenet_val_loss=min(history_lenet_batch['val_loss'])\n",
    "        round_lenet=history_lenet_batch['min_iter']\n",
    "        acc_lenet=history_lenet_batch['test_accuracy']\n",
    "\n",
    "\n",
    "        print('orig min val_loss:{:.3f} iteration:{}, val_accuracy:{:.3f}'.format(orig_val_loss,round_orig,acc_orig))\n",
    "\n",
    "        wt_val_loss=min(history_main_batch[i]['val_loss'])\n",
    "        round_wt=history_main_batch[i]['min_iter']\n",
    "        acc_wt=history_main_batch[i]['test_accuracy']\n",
    "        print('wt min val_loss:{:.3f} iteration:{}, val_accuracy:{:.3f}'.format(wt_val_loss,round_wt,acc_wt))\n",
    "\n",
    "        if round_wt<=round_orig and acc_wt>=acc_orig:\n",
    "            history_main_batch[i]['winning_ticket']=1\n",
    "            print('WINNING WICKET!')\n",
    "            wt+=1\n",
    "        else:\n",
    "            history_main_batch[i]['winning_ticket']=0\n",
    "            print('no winning ticket...')\n",
    "        print()\n",
    "\n",
    "        if round_wt<=round_lenet and acc_wt>=acc_lenet:\n",
    "            history_main_batch[i]['super_winning_ticket']=1\n",
    "            print('SUPER WINNING WICKET!')\n",
    "            swt+=1\n",
    "        else:\n",
    "            history_main_batch[i]['super_winning_ticket']=0\n",
    "\n",
    "        print()\n",
    "    print('percentage of wt:{:.2f}'.format(wt/len(prun_rates)))\n",
    "    print('percentage of swt:{:.2f}'.format(swt/len(prun_rates)))\n",
    "\n",
    "\n",
    "    raw_dir='Raw_Data'\n",
    "\n",
    "    if not os.path.exists(raw_dir):\n",
    "        os.mkdir(raw_dir)\n",
    "        print(\"Directory \" , raw_dir ,  \" Created \")\n",
    "    else:    \n",
    "        print(\"Directory \" , raw_dir ,  \" already exists\")\n",
    "\n",
    "\n",
    "\n",
    "    # What should be the name for the raw data? DEPENDS ON THE EXPERIMENT\n",
    "\n",
    "    filename='{}/Str_{}_pat_{}_layers_{}_{}_round_{}.json'.format(raw_dir,strategy,patience,first_layer,second_layer,exp_round)\n",
    "\n",
    "    encode_save_json(history_main_batch,filename)\n",
    "\n",
    "    #create a new dataframe to inject the values\n",
    "\n",
    "    df=pd.DataFrame()\n",
    "\n",
    "    # just creating a copy \n",
    "    dic=history_main_batch.copy()\n",
    "\n",
    "\n",
    "    #Calculating some metrics \n",
    "    for i in list(dic[1].keys())[5:10]:\n",
    "        df[i]=[dic[1][i][0]]\n",
    "    df['winning_ticket_percentage']=np.mean([dic[i]['winning_ticket'] for i in dic.keys()])\n",
    "    df['super_winning_ticket_percentage']=np.mean([dic[i]['super_winning_ticket'] for i in dic.keys()])\n",
    "    df['round']=exp_round\n",
    "\n",
    "    #creating some colums for the data\n",
    "    if df['winning_ticket_percentage'][0]>0.0:\n",
    "        t=list()\n",
    "        for i in dic.keys():\n",
    "            if dic[i]['winning_ticket']==0:\n",
    "                continue\n",
    "            else:\n",
    "                per=dic[i]['percentage_wts_pruned'][0]\n",
    "                pos=np.argmin(dic[i]['val_loss'])\n",
    "                loss=dic[i]['val_loss'][pos]\n",
    "                acc=dic[i]['test_accuracy']\n",
    "                t.append((per,pos*100,loss,acc))\n",
    "\n",
    "        t.sort(key=lambda x:x[2])\n",
    "        df['min_val_loss_per_pruned']=[t[0][0]]\n",
    "        df['min_val_loss']=[t[0][2]]\n",
    "        df['mean_val_loss']=np.mean([i[2] for i in t])\n",
    "        df['min_val_loss_iteration']=[t[0][1]]\n",
    "        df['mean_val_loss_iteration']=np.mean([i[1] for i in t])\n",
    "        df['min_val_loss_acc']=[t[0][3]]\n",
    "        df['mean_test_acc']=np.mean([i[3] for i in t])\n",
    "\n",
    "\n",
    "\n",
    "    #append the values from this experiment to the main document\n",
    "    df_main=df_main.append(df)\n",
    "\n",
    "    #Update the main results document\n",
    "\n",
    "    df_main.to_csv('{}/{}'.format(data_dirname,summary_data),index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# here the loop ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can see the results here\n",
    "pd.read_csv('{}/{}'.format(data_dirname,summary_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
